!pip install evaluate datasets accelerate torch huggingface_hub
!pip install git+https://github.com/huggingface/transformers 

!python run_clm.py --model_type gpt2 --tokenizer_name openai-community/gpt2 --dataset_name="dustinwloring1988/fineweb-small-test-sample" --output_dir="/output" --config_overrides="n_embd=1024,n_head=8,n_layer=8,n_positions=1024"

or

!python run_clm.py --model_type gpt2 --tokenizer_name dustinwloring1988/llama3-tokenizer --dataset_name="dustinwloring1988/fineweb-small-test-sample" --gradient_checkpointing=True --bf16=False --fp16=False --learning_rate=4e-4 --push_to_hub=True --hub_model_id="dustinwloring1988/test-upload" --push_to_hub_token="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" --weight_decay=0.01 --warmup_steps=128 --logging_steps=5 --per_device_train_batch_size=8 --per_device_eval_batch_size=8 --gradient_accumulation_steps=16 --output_dir="/output" --config_overrides="n_embd=1024,n_head=8,n_layer=8,n_positions=1024,n_inner=4096,scale_attn_by_inverse_layer_idx=True,reorder_and_upcast_attn=True,bos_token_id=128000,eos_token_id=128001,pad_token_id=128001"
